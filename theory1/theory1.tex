\documentclass[12pt]{chmullighw}
\usepackage{sidecap}


% info for header block in upper right hand corner
\name{Chris Mulligan}
\uni{clm2186}
\class{COMS3157 Data Structures \& Algorithms}
\professor{Hershkop}
\assignment{Theory 1}
\duedate{September 30, 2013}

\lstset{language=Java, numbers=none, frame=l, captionpos=n}
\begin{document}
\problemlist{Theory 1} %Give us a nice big title
\begin{enumerate}

\item We use a simplified model because we're primarily interested in
understanding worst case, asymptotic behavior of an algorithm. By ignoring the
details of the specific implementation we can focus on the big picture of how an
algorithm scales, and compare in a general sense. The difference between an algorithm
that completes in $2n$ vs $3n$ does matter, but is completely dwarfed by the
difference between $2n$ and $n^2$, for large values of $n$. 

A more efficient implementation, or slightly better optimization, will only make
a difference on the scale of the fixed cost or multiplier ($3n+30$ to $2.5n+18$),
it won't change the class the algorithm is.


\item The class of an algorithm is asymptotic - as $n$ gets large, what function
is an appropriate upper bound (ignoring multipliers). However this doesn't mean
that on a given dataset, or for a given $n$ of a relatively small size, the
a "worse" function might not perform better. If the \BigO{n \log n} class function
has a high fixed cost, for small values of $n$ that could dwarf the substantially
better asymptotic behavior. 

For example, take our specific functions are \BigO{n \log_2 n + 3000} and
\BigO{n^2+100}. If $n = 50$ then $n \log n$ class function will take take
3282 steps, while the $n^2$ class function takes only 2600 steps. However at
larger values of $n$ the expected behavior arises, for $n = 5\,000$ then $n \log n$
takes $64\,400$ steps, while $n^2$ takes $25\,000\,100$.


\item
\lstinputlisting{Fibonacci.java}

Unsurprisingly the code fails to execute in any reasonable amount of time, even
for a "small" number like $F_{100}$. The results of my attempt at various sizes
show that the function is taking exponentially longer, and is already over a minute
at only $F_{50}$:

\begin{verbatim}
$ for((i=5;i<=51;i+=1)); do java Fibonacci $i; done
\end{verbatim}
\begin{tabular}{l|*{7}{r|}r}
algorithm & 10 & 20 & 30 & 35 & 40 & 45 & 50 & 51\\
\hline
tailed & 0.001 & 0.050 & 0.715 & 2.432 & 18.92 & 211.566 & 2300.641 & 3735.449\\
\hline
tailless & 0.001 & 0.001 & 0.001 & 0.001 & 0.001 & 0.001 & 0.001 & 0.001
\end{tabular}

Graph of the number of seconds taken to calculate $F_n, n=1,...,51$ \\
\includegraphics[height=3.5in]{fibtimes.png}


\item
    \begin{enumerate}
    \item  Given that \BigO{n} $>$ \BigO{\log n}, since this is a worst case scenario
we assume both even and odd execute the \BigO{n} computation, thus the overall
algorithm is, worst case, \BigO{n^2}.

    The best case is that we can assume half the time it executes \BigO{\log n},
    so the overall runtime is $\frac{n}{2}(n + \log n)$.
    \item Without knowing anything about the data, we must assume that all locations
    will contain even numbers - and therefore every computation will take \BigO{n} time. Therefore
    Algorithm C would be \BigO{n^2}.
    \end{enumerate}

\item Assume we have a function \texttt{random()} that returns a random number
in \BigO{1} time.

One method would be to first create the array, $A$, and fill it in order, such that
$a_i = i, i = 1,\ldots,N$, taking \BigO{N} time.
Then iterate through the array, $i = 1,\ldots,N$, for element
$i$ use \texttt{random()} to generate a random integer $j \in (1, N)$ and swap
$a_i$ with $a_j$. The run time for a single element is a constant for generating
the random number, and a constant for the swap. Thus the overall runtime is
simply \BigO{N}.

Another (worse) method is to create the basic array, $A$ as described above, where
$a_i = i, i=1,\ldots,N$, taking \BigO{N}. Then create an empty array of size N,
$B$, taking \BigO{1}. For $i = 1,\ldots,N$ use \texttt{random()} to select a
random index $r \in [1, N-i]$ of the initial array $A$, remove the element $a_r$
and insert it into the next slot $b_i$. However array $A$ must be collapsed after
each removal so it's not sparse. This results in an overall \BigO{N^2} runtime.


\item Number the elements $e_i, i=1,...,N$. Starting with the first element test
whether each subsequent element, $e_j \mid j > 1$ can be subtracted from this element (or
vice-versa) to equal $K$. If not, proceed with the second element and test all
the remaining elements from $e_3$. In other words test:\\
$(\forall i)(\forall j : j > i)(e_i - e_j = K$ OR $e_j - e_i = K)$

Since in the worst case there is no combination that equals K every element must
be tested against every other element, resulting in \BigO{n^2} run time.


\end{enumerate} %end of questions
\end{document}
